{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-05T20:04:02.637586Z",
     "iopub.status.busy": "2025-05-05T20:04:02.637368Z",
     "iopub.status.idle": "2025-05-05T20:04:09.640312Z",
     "shell.execute_reply": "2025-05-05T20:04:09.639649Z",
     "shell.execute_reply.started": "2025-05-05T20:04:02.637564Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:04:09.642270Z",
     "iopub.status.busy": "2025-05-05T20:04:09.641987Z",
     "iopub.status.idle": "2025-05-05T20:04:55.443259Z",
     "shell.execute_reply": "2025-05-05T20:04:55.442470Z",
     "shell.execute_reply.started": "2025-05-05T20:04:09.642252Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 20:04:27.675539: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746475468.147716      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746475468.290876      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "import os\n",
    "import wandb\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "import torch\n",
    "import math\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoConfig,\n",
    "    GPT2ForSequenceClassification,\n",
    "    Trainer, \n",
    "    TrainingArguments\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:04:55.444187Z",
     "iopub.status.busy": "2025-05-05T20:04:55.443965Z",
     "iopub.status.idle": "2025-05-05T20:04:59.370042Z",
     "shell.execute_reply": "2025-05-05T20:04:59.369456Z",
     "shell.execute_reply.started": "2025-05-05T20:04:55.444169Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb8a81dc414e4fed80ae928f5c4b820b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/7.81k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "929d1b88256145129264fce6a1e4ed4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee974e30f3984011bf451ea38f60d1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "181dd374b0dc44149620adc813072da4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unsupervised-00000-of-00001.parquet:   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "022aba99ba3148169298784be4212ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13dd80fe640547e986d336d2fcb4eb54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a81607470366486b8330594123a247c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86acb72951ca4e2b8377ff2340047a93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa46434ceaa34985b7e36498efa60ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 12500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 42\n",
    "\n",
    "dataset = load_dataset(\"imdb\")\n",
    "\n",
    "train_dataset = dataset[\"train\"]\n",
    "positive = train_dataset.filter(lambda x: x[\"label\"] == 1)\n",
    "negative = train_dataset.filter(lambda x: x[\"label\"] == 0)\n",
    "\n",
    "subset_pos = positive.shuffle(seed=seed).select(range(6250))\n",
    "subset_neg = negative.shuffle(seed=seed).select(range(6250))\n",
    "\n",
    "balanced_subset = concatenate_datasets([subset_pos, subset_neg]).shuffle(seed=seed)\n",
    "dataset[\"train\"] = balanced_subset\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:04:59.370896Z",
     "iopub.status.busy": "2025-05-05T20:04:59.370642Z",
     "iopub.status.idle": "2025-05-05T20:04:59.376405Z",
     "shell.execute_reply": "2025-05-05T20:04:59.375607Z",
     "shell.execute_reply.started": "2025-05-05T20:04:59.370879Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'From around the time Europe began fighting World War II, until the war\\'s end, Hollywood (with significant prodding from the government) made tons of movies which were designed to try and get young men to enlist in the Army, by making the life of a serviceman appear \"cool.\" This is by far the sloppiest, implying that the life of a soldier is devoid of work, you get the best food, and you get to lie around all day listening to Ann Miller on the radio. I am far too young to have participated in WWII, but I think that there was more to it than that. There is the barest cat\\'s whisker of a plot, and a bunch of musical numbers featuring some of the day\\'s leading acts.<br /><br />I think that by 1943, even the most naive of civvies knew that there was more going on overseas than the wacky hijinks portrayed in this movie. While I am sure that it was meant to be viewed as escapist entertainment, I can\\'t help but wonder if the family and loved ones of men fighting in the war, were amused or repulsed by this trivialization of their loved ones\\' sacrifice.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:04:59.381601Z",
     "iopub.status.busy": "2025-05-05T20:04:59.381319Z",
     "iopub.status.idle": "2025-05-05T20:05:00.196282Z",
     "shell.execute_reply": "2025-05-05T20:05:00.195491Z",
     "shell.execute_reply.started": "2025-05-05T20:04:59.381574Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec142f0b03b423a92e171a79d0c2ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.16k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38837c07033a4417b9ed6312e78ccf45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/3.60M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "667c683978374cba929d23cf3d04c61a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/692 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"linhlinhle997/gpt2-small-c4-pretrained\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:05:00.197175Z",
     "iopub.status.busy": "2025-05-05T20:05:00.196976Z",
     "iopub.status.idle": "2025-05-05T20:05:44.445831Z",
     "shell.execute_reply": "2025-05-05T20:05:44.445227Z",
     "shell.execute_reply.started": "2025-05-05T20:05:00.197159Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6030812eb2734fa1b4ab3b5a54a2b9fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e70dae28b7b94d9f8d5e41f7f451c107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aa3dc38e6da4795a999c338f39a0f10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 12500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(example):\n",
    "    return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True, max_length=256)\n",
    "\n",
    "tokenized_ds = dataset.map(tokenize, batched=True)\n",
    "tokenized_ds = tokenized_ds.remove_columns([\"text\"])\n",
    "tokenized_ds.set_format(\"torch\")\n",
    "\n",
    "tokenized_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:05:44.446873Z",
     "iopub.status.busy": "2025-05-05T20:05:44.446580Z",
     "iopub.status.idle": "2025-05-05T20:05:45.919219Z",
     "shell.execute_reply": "2025-05-05T20:05:45.918644Z",
     "shell.execute_reply.started": "2025-05-05T20:05:44.446846Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f95a9e5521ec4848be1f357fd049480a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/790 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a9a34cdae734c318a33a65072dc700a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/180M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at linhlinhle997/gpt2-small-c4-pretrained and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2, id2label=id2label, label2id=label2id\n",
    ")\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:05:45.920390Z",
     "iopub.status.busy": "2025-05-05T20:05:45.920105Z",
     "iopub.status.idle": "2025-05-05T20:05:45.925352Z",
     "shell.execute_reply": "2025-05-05T20:05:45.924605Z",
     "shell.execute_reply.started": "2025-05-05T20:05:45.920359Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2ForSequenceClassification(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 512)\n",
       "    (wpe): Embedding(512, 512)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-5): 6 x GPT2Block(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=1536, nx=512)\n",
       "          (c_proj): Conv1D(nf=512, nx=512)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=2048, nx=512)\n",
       "          (c_proj): Conv1D(nf=512, nx=2048)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (score): Linear(in_features=512, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:05:45.926424Z",
     "iopub.status.busy": "2025-05-05T20:05:45.926239Z",
     "iopub.status.idle": "2025-05-05T20:05:46.284262Z",
     "shell.execute_reply": "2025-05-05T20:05:46.283713Z",
     "shell.execute_reply.started": "2025-05-05T20:05:45.926410Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "065e854377474c87b6736f22d5ac59be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    return accuracy.compute(predictions=preds, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:06:20.962421Z",
     "iopub.status.busy": "2025-05-05T20:06:20.961866Z",
     "iopub.status.idle": "2025-05-05T20:06:20.965921Z",
     "shell.execute_reply": "2025-05-05T20:06:20.965308Z",
     "shell.execute_reply.started": "2025-05-05T20:06:20.962400Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "project_name = \"gpt2-c4-imdb\"\n",
    "run_name = \"finetuning-gpt2-small-imdb-v1\"\n",
    "model_name = \"gpt2-small-imdb-finetuning\"\n",
    "\n",
    "os.environ[\"WANDB_API_KEY\"] = \"\"\n",
    "os.environ[\"WANDB_PROJECT\"] = project_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:06:46.918982Z",
     "iopub.status.busy": "2025-05-05T20:06:46.918468Z",
     "iopub.status.idle": "2025-05-05T20:35:47.428229Z",
     "shell.execute_reply": "2025-05-05T20:35:47.427527Z",
     "shell.execute_reply.started": "2025-05-05T20:06:46.918958Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlinhlinh-le997\u001b[0m (\u001b[33mlinhlinh-le997-prime-labo\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250505_200653-l3ucck2j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/linhlinh-le997-prime-labo/gpt2-c4-imdb/runs/l3ucck2j' target=\"_blank\">finetuning-gpt2-small-imdb-v1</a></strong> to <a href='https://wandb.ai/linhlinh-le997-prime-labo/gpt2-c4-imdb' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/linhlinh-le997-prime-labo/gpt2-c4-imdb' target=\"_blank\">https://wandb.ai/linhlinh-le997-prime-labo/gpt2-c4-imdb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/linhlinh-le997-prime-labo/gpt2-c4-imdb/runs/l3ucck2j' target=\"_blank\">https://wandb.ai/linhlinh-le997-prime-labo/gpt2-c4-imdb/runs/l3ucck2j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1960' max='1960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1960/1960 28:43, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.523200</td>\n",
       "      <td>0.493288</td>\n",
       "      <td>0.777400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.327100</td>\n",
       "      <td>0.445221</td>\n",
       "      <td>0.826480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.182500</td>\n",
       "      <td>0.598824</td>\n",
       "      <td>0.789080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.565549</td>\n",
       "      <td>0.815080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.071200</td>\n",
       "      <td>1.641583</td>\n",
       "      <td>0.792400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.106100</td>\n",
       "      <td>2.280513</td>\n",
       "      <td>0.812920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.098700</td>\n",
       "      <td>2.935570</td>\n",
       "      <td>0.810480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>3.172876</td>\n",
       "      <td>0.802560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.032300</td>\n",
       "      <td>3.190399</td>\n",
       "      <td>0.803320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>3.099252</td>\n",
       "      <td>0.807680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1960, training_loss=0.1525110095131154, metrics={'train_runtime': 1739.2616, 'train_samples_per_second': 71.87, 'train_steps_per_second': 1.127, 'total_flos': 3631939584000000.0, 'train_loss': 0.1525110095131154, 'epoch': 10.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=model_name,\n",
    "    run_name=run_name,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    "    save_total_limit=1,\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:35:47.429799Z",
     "iopub.status.busy": "2025-05-05T20:35:47.429526Z",
     "iopub.status.idle": "2025-05-05T20:35:47.917201Z",
     "shell.execute_reply": "2025-05-05T20:35:47.916655Z",
     "shell.execute_reply.started": "2025-05-05T20:35:47.429782Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(model_name)\n",
    "model.save_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:51:29.054815Z",
     "iopub.status.busy": "2025-05-05T20:51:29.054294Z",
     "iopub.status.idle": "2025-05-05T20:51:29.214924Z",
     "shell.execute_reply": "2025-05-05T20:51:29.214360Z",
     "shell.execute_reply.started": "2025-05-05T20:51:29.054792Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = GPT2ForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:51:30.033025Z",
     "iopub.status.busy": "2025-05-05T20:51:30.032784Z",
     "iopub.status.idle": "2025-05-05T20:51:30.307632Z",
     "shell.execute_reply": "2025-05-05T20:51:30.306928Z",
     "shell.execute_reply.started": "2025-05-05T20:51:30.033008Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"This movie was absolutely terrible and boring.\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "    pred = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "result = \"positive\" if pred == 1 else \"negative\"\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
